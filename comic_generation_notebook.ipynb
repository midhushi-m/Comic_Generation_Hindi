{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8rUZRmLSceRYbS2tWSzNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midhushi-m/Comic_Generation_Hindi/blob/main/comic_generation_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Mount Google Drive\n",
        "\n",
        "# Change directory to your model folder\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/character\")\n"
      ],
      "metadata": {
        "id": "dNZfCnypncqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
      ],
      "metadata": {
        "id": "aoakVG5_6JiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import json\n",
        "import re\n",
        "\n",
        "def extract_characters(text):\n",
        "    # Simple pattern to catch names before verbs like 'कहता है', 'कहती है'\n",
        "    name_pattern = r\"(\\w+)\\s+(कहता है|कहती है|बोला|बोली)\"\n",
        "    characters = set()\n",
        "\n",
        "    # Find all names before dialogue markers\n",
        "    for match in re.finditer(name_pattern, text):\n",
        "        characters.add(match.group(1))\n",
        "\n",
        "    # Additional manual patterns for this specific story\n",
        "    if \"राम\" in text:\n",
        "        characters.add(\"राम\")\n",
        "    if \"कालू\" in text:\n",
        "        characters.add(\"कालू\")\n",
        "    if \"सोनी\" in text:\n",
        "        characters.add(\"सोनी\")\n",
        "\n",
        "    return list(characters)\n",
        "\n",
        "def split_scenes(text):\n",
        "    sentences = [s.strip() + \"।\" for s in text.split(\"।\") if s.strip()]\n",
        "    scenes = []\n",
        "    all_characters = extract_characters(text)\n",
        "    current_location = \"अज्ञात\"\n",
        "\n",
        "    for i, sentence in enumerate(sentences, 1):\n",
        "        # Update location\n",
        "        if \"जंगल\" in sentence:\n",
        "            current_location = \"जंगल\"\n",
        "        elif \"झील\" in sentence:\n",
        "            current_location = \"झील\"\n",
        "\n",
        "        # Characters in scene\n",
        "        chars_in_scene = [c for c in all_characters if c in sentence]\n",
        "        if \"तीनों\" in sentence:\n",
        "            chars_in_scene = all_characters\n",
        "\n",
        "        # Detect dialogue between single quotes\n",
        "        dialogue = None\n",
        "        if \"'\" in sentence:\n",
        "            parts = sentence.split(\"'\")\n",
        "            if len(parts) >= 3:\n",
        "                dialogue_text = parts[1].strip(\"।\")\n",
        "                speaker_match = re.search(r\"(\\w+)\\s+(?:कहता है|कहती है|बोलता है|बोलती है)\", sentence)\n",
        "                speaker = speaker_match.group(1) if speaker_match else \"unknown\"\n",
        "                dialogue = {\n",
        "                    \"character\": speaker,\n",
        "                    \"text\": dialogue_text,\n",
        "                    \"emotion\": detect_emotion(dialogue_text),\n",
        "                    \"position\": detect_position(sentence, speaker)\n",
        "                }\n",
        "\n",
        "\n",
        "        scene_data = {\n",
        "            \"scene_number\": i,\n",
        "            \"location\": current_location,\n",
        "            \"scene_text\": sentence,\n",
        "            \"characters_in_scene\": chars_in_scene,\n",
        "            \"emotion\": detect_scene_emotion(sentence),\n",
        "            \"position\": detect_scene_position(sentence),\n",
        "            \"dialogues\": [dialogue] if dialogue else []\n",
        "        }\n",
        "\n",
        "        scenes.append(scene_data)\n",
        "\n",
        "    return scenes\n",
        "\n",
        "# Helper functions for emotion and position detection\n",
        "def detect_emotion(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in [\"खुश\", \"हँस\", \"मुस्कुर\"]):\n",
        "        return \"happy\"\n",
        "    elif any(word in text for word in [\"डर\", \"भय\"]):\n",
        "        return \"scared\"\n",
        "    elif any(word in text for word in [\"दुख\", \"उदास\"]):\n",
        "        return \"sad\"\n",
        "    return \"smile\"  # Default\n",
        "\n",
        "def detect_position(sentence, character):\n",
        "    sentence = sentence.lower()\n",
        "    if \"बैठ\" in sentence:\n",
        "        return \"sitting\"\n",
        "    elif \"लेट\" in sentence:\n",
        "        return \"lying\"\n",
        "    elif \"चल\" in sentence:\n",
        "        return \"walking\"\n",
        "    return \"standing\"  # Default\n",
        "\n",
        "def detect_scene_emotion(sentence):\n",
        "    # Similar logic as detect_emotion but for whole scene\n",
        "    return detect_emotion(sentence)\n",
        "\n",
        "def detect_scene_position(sentence):\n",
        "    # Similar logic as detect_position but for whole scene\n",
        "    if \"बैठ\" in sentence:\n",
        "        return \"sitting\"\n",
        "    return \"standing\"\n",
        "\n",
        "# Hindi story\n",
        "hindi_story = \"\"\"\n",
        "राम, एक सुंदर लड़का, जंगल में अपने बात करने वाले कुत्ते कालू के साथ चल रहा है।\n",
        "वहाँ उसकी मुलाकात सोनी नाम की एक लड़की से होती है। कालू कहता है 'नमस्ते'। सोनी कहती है 'हाय'।\n",
        "बाद में तीनों एक झील के पास बैठते हैं और बातें करते हैं।\n",
        "\"\"\"\n",
        "\n",
        "# Process the story\n",
        "characters = extract_characters(hindi_story)\n",
        "scenes = split_scenes(hindi_story)\n",
        "\n",
        "story_data = {\n",
        "    \"original_hindi\": hindi_story.strip(),\n",
        "    \"characters\": characters,\n",
        "    \"scenes\": scenes\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "with open(\"hindi_story_processed.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(story_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"✅ Hindi story processed successfully!\")'''"
      ],
      "metadata": {
        "id": "MzeXr7PT6VYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def extract_characters(text):\n",
        "    name_pattern = r\"(\\w+)\\s+(कहता है|कहती है|बोला|बोली|बोलता है|बोलती है)\"\n",
        "    characters = set()\n",
        "\n",
        "    for match in re.finditer(name_pattern, text):\n",
        "        characters.add(match.group(1))\n",
        "\n",
        "    # Additional manual patterns for this specific story\n",
        "    for name in [\"राम\", \"कालू\", \"सोनी\"]:\n",
        "        if name in text:\n",
        "            characters.add(name)\n",
        "\n",
        "    return list(characters)\n",
        "\n",
        "def split_scenes(text):\n",
        "    sentences = [s.strip() + \"।\" for s in text.split(\"।\") if s.strip()]\n",
        "    scenes = []\n",
        "    all_characters = extract_characters(text)\n",
        "    current_location = \"अज्ञात\"\n",
        "\n",
        "    for i, sentence in enumerate(sentences, 1):\n",
        "        if \"जंगल\" in sentence:\n",
        "            current_location = \"जंगल\"\n",
        "        elif \"झील\" in sentence:\n",
        "            current_location = \"झील\"\n",
        "\n",
        "        chars_in_scene = [c for c in all_characters if c in sentence]\n",
        "        if \"तीनों\" in sentence or \"सभी\" in sentence:\n",
        "            chars_in_scene = all_characters\n",
        "\n",
        "        # Detect dialogue text inside single quotes\n",
        "        dialogues = []\n",
        "        matches = re.findall(r\"'(.*?)'\", sentence)\n",
        "        for d in matches:\n",
        "            dialogues.append(d.strip(\"।\"))\n",
        "\n",
        "        scene_data = {\n",
        "            \"scene_number\": i,\n",
        "            \"location\": current_location,\n",
        "            \"scene_text\": sentence,\n",
        "            \"characters_in_scene\": chars_in_scene,\n",
        "            \"emotion\": detect_scene_emotion(sentence),\n",
        "            \"position\": detect_scene_position(sentence),\n",
        "            \"dialogues\": dialogues\n",
        "        }\n",
        "\n",
        "        scenes.append(scene_data)\n",
        "\n",
        "    return scenes\n",
        "\n",
        "def detect_emotion(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in [\"खुश\", \"हँस\", \"मुस्कुर\"]):\n",
        "        return \"happy\"\n",
        "    elif any(word in text for word in [\"डर\", \"भय\"]):\n",
        "        return \"scared\"\n",
        "    elif any(word in text for word in [\"दुख\", \"उदास\"]):\n",
        "        return \"sad\"\n",
        "    return \"smile\"\n",
        "\n",
        "def detect_position(sentence, character):\n",
        "    sentence = sentence.lower()\n",
        "    if \"बैठ\" in sentence:\n",
        "        return \"sitting\"\n",
        "    elif \"लेट\" in sentence:\n",
        "        return \"lying\"\n",
        "    elif \"चल\" in sentence:\n",
        "        return \"walking\"\n",
        "    return \"standing\"\n",
        "\n",
        "def detect_scene_emotion(sentence):\n",
        "    return detect_emotion(sentence)\n",
        "\n",
        "def detect_scene_position(sentence):\n",
        "    if \"बैठ\" in sentence:\n",
        "        return \"sitting\"\n",
        "    return \"standing\"\n",
        "\n",
        "# Hindi story\n",
        "hindi_story = \"\"\"\n",
        "राम, एक सुंदर लड़का, जंगल में अपने बात करने वाले कुत्ते कालू के साथ चल रहा है।\n",
        "वहाँ उसकी मुलाकात सोनी नाम की एक लड़की से होती है। कालू कहता है 'नमस्ते'। सोनी कहती है 'हाय'।\n",
        "बाद में तीनों एक झील के पास बैठते हैं और बातें करते हैं।\n",
        "\"\"\"\n",
        "\n",
        "characters = extract_characters(hindi_story)\n",
        "scenes = split_scenes(hindi_story)\n",
        "\n",
        "story_data = {\n",
        "    \"original_hindi\": hindi_story.strip(),\n",
        "    \"characters\": characters,\n",
        "    \"scenes\": scenes\n",
        "}\n",
        "\n",
        "with open(\"hindi_story.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(story_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"✅ Hindi story processed successfully!\")\n"
      ],
      "metadata": {
        "id": "jZjUWucW_c6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate bitsandbytes xformers safetensors\n",
        "!pip install peft\n"
      ],
      "metadata": {
        "id": "5GeW1YDhB7yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.nn import functional as F\n",
        "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ✅ Set Random Seeds for Reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    dataset_dir = \"/content/drive/MyDrive/character/train\"\n",
        "    output_dir = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    batch_size = 1\n",
        "    gradient_accumulation_steps = 4\n",
        "    learning_rate = 1e-5\n",
        "    num_epochs = 10\n",
        "    mixed_precision = \"fp16\"\n",
        "    lora_r = 16\n",
        "    lora_alpha = 32\n",
        "    lora_dropout = 0.1\n",
        "    target_modules = [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]\n",
        "    validation_steps = 100\n",
        "    characters = sorted(os.listdir(dataset_dir))  # Sort characters for consistent order\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# ✅ Load Stable Diffusion Model\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    config.model_id, torch_dtype=torch.float16 if config.mixed_precision == \"fp16\" else torch.float32\n",
        ")\n",
        "pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# ✅ Apply LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=config.lora_r,\n",
        "    lora_alpha=config.lora_alpha,\n",
        "    target_modules=config.target_modules,\n",
        "    lora_dropout=config.lora_dropout\n",
        ")\n",
        "pipe.unet = get_peft_model(pipe.unet, lora_config)\n",
        "pipe.unet.train()\n",
        "\n",
        "# ✅ Define Data Augmentation & Custom Image Dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, character, transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, character)\n",
        "        self.character = character\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "        self.labels = []\n",
        "\n",
        "        for emotion in sorted(os.listdir(self.root_dir)):\n",
        "            emotion_path = os.path.join(self.root_dir, emotion)\n",
        "            if not os.path.isdir(emotion_path):  # ✅ Skip files\n",
        "                continue\n",
        "\n",
        "            emotion_path = os.path.join(self.root_dir, emotion)\n",
        "            if not os.path.isdir(emotion_path):\n",
        "                continue\n",
        "\n",
        "            for file in os.listdir(emotion_path):\n",
        "                if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                    self.image_files.append(os.path.join(emotion_path, file))\n",
        "                    self.labels.append(f\"{character}_{emotion}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        prompt = f\"A {label.split('_')[1]} {label.split('_')[0]} in comic style\"\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {\"pixel_values\": image, \"prompt\": prompt}\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# ✅ Training Loop for Each Character\n",
        "for character in config.characters:\n",
        "    print(f\"\\n🚀 Training for character: {character}\")\n",
        "    char_dataset = ImageDataset(config.dataset_dir, character, transform=transform)\n",
        "    char_dataloader = DataLoader(char_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=config.learning_rate, weight_decay=0.01)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(char_dataloader) * config.num_epochs // config.gradient_accumulation_steps)\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        progress_bar = tqdm(total=len(char_dataloader), desc=f\"{character} - Epoch {epoch+1}\")\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for step, batch in enumerate(char_dataloader):\n",
        "            pixel_values = batch[\"pixel_values\"].to(\"cuda\").half()\n",
        "            latents = pipe.vae.encode(pixel_values).latent_dist.sample() * pipe.vae.config.scaling_factor\n",
        "            timesteps = torch.randint(0, pipe.scheduler.config.num_train_timesteps, (latents.shape[0],), device=\"cuda\").long()\n",
        "            noise = torch.randn_like(latents)\n",
        "            noisy_latents = pipe.scheduler.add_noise(latents, noise, timesteps)\n",
        "            text_input = pipe.tokenizer(batch[\"prompt\"], padding=\"max_length\", max_length=pipe.tokenizer.model_max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "            encoder_hidden_states = pipe.text_encoder(**text_input).last_hidden_state\n",
        "            model_pred = pipe.unet(noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states).sample\n",
        "            loss = F.mse_loss(model_pred, noise) / config.gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(pipe.unet.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "        progress_bar.close()\n",
        "\n",
        "    # ✅ Save Checkpoint for Each Character\n",
        "    char_save_dir = os.path.join(config.output_dir, f\"{character}_lora\")\n",
        "    os.makedirs(char_save_dir, exist_ok=True)\n",
        "    lora_save_dir = os.path.join(char_save_dir, \"lora_adapter\")\n",
        "    pipe.unet.save_pretrained(lora_save_dir)\n",
        "    print(f\"✅ LoRA model saved for {character} at {char_save_dir}\")\n",
        "\n",
        "print(\"🎉 Training Completed for All Characters!\")\n"
      ],
      "metadata": {
        "id": "Seod4FxpCGre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ✅ Load Model for Inference with LoRA for a specific character\n",
        "def load_model_for_inference(base_model_path, lora_weights_path, character):\n",
        "    \"\"\"Loads the base Stable Diffusion model and applies LoRA weights for the specific character.\"\"\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(base_model_path, torch_dtype=torch.float16)\n",
        "    pipe.to(\"cuda\")\n",
        "\n",
        "    # ✅ Define the correct path for LoRA adapter based on character\n",
        "    lora_adapter_path = os.path.join(lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "\n",
        "    # ✅ Print the path for verification\n",
        "    print(f\"🔍 Checking LoRA adapter path: {lora_adapter_path}\")\n",
        "\n",
        "    # ✅ Check if the LoRA adapter exists and load it\n",
        "    if os.path.exists(lora_adapter_path):\n",
        "        print(f\"✅ Loading LoRA adapter for {character} from {lora_adapter_path}...\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_adapter_path)\n",
        "        pipe.unet = pipe.unet.merge_and_unload()\n",
        "        print(f\"✅ LoRA successfully merged for {character}.\")\n",
        "    else:\n",
        "        print(f\"❌ LoRA adapter for {character} not found at {lora_adapter_path}.\")\n",
        "\n",
        "    return pipe\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"  # Base model for Stable Diffusion\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"  # Correct path where LoRA weights are saved\n",
        "    output_dir = \"./panels/\"  # Folder to save the generated comic panels\n",
        "    json_file = \"hindi_story.json\"  # Input JSON file for comic generation\n",
        "\n",
        "# ✅ Ensure output directory exists\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Generate image for each scene based on the character-specific model\n",
        "def generate_comic_from_json(json_file):\n",
        "    \"\"\"Reads a JSON file and generates comic panels for each scene based on character-specific models.\"\"\"\n",
        "\n",
        "    # ✅ Load JSON data\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    scenes = data[\"scenes\"]\n",
        "    location = \"\"  # Keep track of the location\n",
        "\n",
        "    # ✅ Generate panels for each scene\n",
        "    for scene in scenes:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "\n",
        "        # ✅ Check if dialogues exist and are in the correct format\n",
        "        if scene.get(\"dialogues\"):\n",
        "            if isinstance(scene[\"dialogues\"], list):\n",
        "                # If dialogues are a list of strings, use the first one for dialogue_text\n",
        "                dialogue_text = scene[\"dialogues\"][0] if scene[\"dialogues\"] else \"No dialogue found\"\n",
        "                character = \"default_character\"  # Use a default character if not available\n",
        "            else:\n",
        "                # If dialogues are in a dictionary format, extract character and text\n",
        "                character = scene[\"dialogues\"].get(\"character\", \"default_character\")\n",
        "                dialogue_text = scene[\"dialogues\"].get(\"text\", \"No dialogue found\")\n",
        "        else:\n",
        "            # If no dialogues found, use a default character and dialogue\n",
        "            character = \"default_character\"\n",
        "            dialogue_text = \"No dialogue found\"\n",
        "\n",
        "        # ✅ If location is not specified, use the last known location\n",
        "        if 'location' in scene and scene['location']:\n",
        "            location = scene['location']\n",
        "\n",
        "        if location:\n",
        "            # Add location to scene_text if not already part of it\n",
        "            if location.lower() not in scene_text.lower():\n",
        "                scene_text = f\"In the {location}, {scene_text}\"\n",
        "\n",
        "        # ✅ Load the character-specific model for inference\n",
        "        inference_pipe = load_model_for_inference(Config.base_model, Config.lora_weights_path, character)\n",
        "\n",
        "        # ✅ Add comic-style details to the prompt using scene_text and dialogue_text\n",
        "        prompt = (\n",
        "            f\"{scene_text}, with dialogue: '{dialogue_text}', highly detailed comic-style illustration, \"\n",
        "            \"vibrant colors, inked outlines, dynamic composition, expressive characters, in the style of graphic novels.\"\n",
        "        )\n",
        "\n",
        "        print(f\"🎨 Generating panel for Scene {scene_number} with character {character}: {prompt}\")\n",
        "\n",
        "        # ✅ Clear VRAM before generating\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # ✅ Generate image\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            image = inference_pipe(prompt).images[0]\n",
        "\n",
        "        # ✅ Save the image in BMP format\n",
        "        output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "        image.save(output_path)\n",
        "        print(f\"✅ Panel {scene_number} for {character} saved: {output_path}\")\n",
        "\n",
        "    print(\"🎉 All comic panels generated successfully!\")\n",
        "\n",
        "# ✅ Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)\n"
      ],
      "metadata": {
        "id": "PS15hnlFGwWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ✅ Load Model for Inference with LoRA for a specific character\n",
        "def load_model_for_inference(base_model_path, lora_weights_path, character):\n",
        "    \"\"\"Loads the base Stable Diffusion model and applies LoRA weights for the specific character.\"\"\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(base_model_path, torch_dtype=torch.float16)\n",
        "    pipe.to(\"cuda\")\n",
        "\n",
        "    # ✅ Define the correct path for LoRA adapter based on character\n",
        "    lora_adapter_path = os.path.join(lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "\n",
        "    # ✅ Print the path for verification\n",
        "    print(f\"🔍 Checking LoRA adapter path: {lora_adapter_path}\")\n",
        "\n",
        "    # ✅ Check if the LoRA adapter exists and load it\n",
        "    if os.path.exists(lora_adapter_path):\n",
        "        print(f\"✅ Loading LoRA adapter for {character} from {lora_adapter_path}...\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_adapter_path)\n",
        "        pipe.unet = pipe.unet.merge_and_unload()\n",
        "        print(f\"✅ LoRA successfully merged for {character}.\")\n",
        "    else:\n",
        "        print(f\"❌ LoRA adapter for {character} not found at {lora_adapter_path}.\")\n",
        "\n",
        "    return pipe\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"  # Base model for Stable Diffusion\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"  # Correct path where LoRA weights are saved\n",
        "    output_dir = \"./panels/\"  # Folder to save the generated comic panels\n",
        "    json_file = \"hindi_story.json\"  # Input JSON file for comic generation\n",
        "\n",
        "# ✅ Ensure output directory exists\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Generate image for each scene based on the character-specific model\n",
        "def generate_comic_from_json(json_file):\n",
        "    \"\"\"Reads a JSON file and generates comic panels for each scene based on character-specific models.\"\"\"\n",
        "\n",
        "    # ✅ Load JSON data\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    scenes = data[\"scenes\"]\n",
        "    location = \"\"  # Keep track of the location\n",
        "\n",
        "    # ✅ Define Hindi-to-English character mapping for LoRA\n",
        "    character_map = {\n",
        "        \"राम\": \"Ram\",\n",
        "        \"कालू\": \"Bruno\",\n",
        "        \"सोनी\": \"Tina\"\n",
        "    }\n",
        "\n",
        "    # ✅ Generate panels for each scene\n",
        "    for scene in scenes:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "\n",
        "        # ✅ Check if dialogues exist, and get the character if dialogues are present\n",
        "        if scene[\"dialogues\"]:\n",
        "            # If dialogue is just a list, assume one character is speaking\n",
        "            if isinstance(scene[\"dialogues\"][0], dict) and \"character\" in scene[\"dialogues\"][0]:\n",
        "                character = scene[\"dialogues\"][0][\"character\"]\n",
        "            else:\n",
        "                character = scene[\"characters_in_scene\"][0]\n",
        "        else:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else \"default_character\"\n",
        "            print(f\"⚠️ No dialogues found. Using default character: {character}\")\n",
        "\n",
        "        # ✅ If location is not specified, use the last known location\n",
        "        if 'location' in scene and scene['location']:\n",
        "            location = scene['location']\n",
        "\n",
        "        if location:\n",
        "            # Add location to scene_text if not already part of it\n",
        "            if location.lower() not in scene_text.lower():\n",
        "                scene_text = f\"In the {location}, {scene_text}\"\n",
        "\n",
        "        # ✅ Map Hindi character to English LoRA folder name\n",
        "        mapped_character = character_map.get(character, character)\n",
        "\n",
        "        # ✅ Load the character-specific model for inference\n",
        "        inference_pipe = load_model_for_inference(Config.base_model, Config.lora_weights_path, mapped_character)\n",
        "\n",
        "        # ✅ Add comic-style details to the prompt\n",
        "        prompt = (\n",
        "            f\"{scene_text}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, in the style of graphic novels.\"\n",
        "        )\n",
        "\n",
        "        print(f\"🎨 Generating panel for Scene {scene_number} with character {character}: {prompt}\")\n",
        "\n",
        "        # ✅ Clear VRAM before generating\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # ✅ Generate image\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            image = inference_pipe(prompt).images[0]\n",
        "\n",
        "        # ✅ Save the image in BMP format\n",
        "        output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "        image.save(output_path)\n",
        "        print(f\"✅ Panel {scene_number} for {character} saved: {output_path}\")\n",
        "\n",
        "    print(\"🎉 All comic panels generated successfully!\")\n",
        "\n",
        "# ✅ Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)\n"
      ],
      "metadata": {
        "id": "B-PzFCKwKUnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "id": "w5ai-IVBQmkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from googletrans import Translator\n",
        "\n",
        "def translate_story(input_file, output_file):\n",
        "    # Initialize translator\n",
        "    translator = Translator()\n",
        "\n",
        "    # Load Hindi story\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        hindi_data = json.load(f)\n",
        "\n",
        "    # Translate the main story text\n",
        "    translated_story = translator.translate(hindi_data['original_hindi'], src='hi', dest='en').text\n",
        "\n",
        "    # Prepare English data structure\n",
        "    english_data = {\n",
        "        \"original_english\": translated_story,\n",
        "        \"characters\": [],\n",
        "        \"scenes\": []\n",
        "    }\n",
        "\n",
        "    # Translate character names (we'll keep these as is for LoRA mapping)\n",
        "    english_data['characters'] = hindi_data['characters']\n",
        "\n",
        "    # Translate each scene\n",
        "    for scene in hindi_data['scenes']:\n",
        "        translated_scene = {\n",
        "            \"scene_number\": scene[\"scene_number\"],\n",
        "            \"location\": translator.translate(scene[\"location\"], src='hi', dest='en').text,\n",
        "            \"scene_text\": translator.translate(scene[\"scene_text\"], src='hi', dest='en').text,\n",
        "            \"characters_in_scene\": scene[\"characters_in_scene\"],  # Keep original for mapping\n",
        "            \"emotion\": scene[\"emotion\"],  # Already in English\n",
        "            \"position\": scene[\"position\"],  # Already in English\n",
        "            \"dialogues\": [translator.translate(d, src='hi', dest='en').text for d in scene[\"dialogues\"]]\n",
        "        }\n",
        "        english_data['scenes'].append(translated_scene)\n",
        "\n",
        "    # Save translated story\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(english_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"✅ Successfully translated {input_file} to {output_file}\")\n",
        "\n",
        "# Usage\n",
        "translate_story(\"hindi_story.json\", \"translated_story.json\")"
      ],
      "metadata": {
        "id": "O0tBkWdZXV-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJI0g-B3cVvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Your Hindi to English character mapping\n",
        "character_map = {\n",
        "    \"कालू\": \"Bruno\",\n",
        "    \"सोनी\": \"Tina\",\n",
        "    \"राम\": \"Ram\"\n",
        "}\n",
        "\n",
        "# Optional: LoRA adapter mapping (if needed later)\n",
        "lora_model_map = {\n",
        "    \"Kalu\": \"Bruno\",\n",
        "    \"Soni\": \"Tina\",\n",
        "    \"Ram\": \"Ram\"\n",
        "}\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"translated_story.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Update character names in each scene\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene[\"characters_in_scene\"] = [character_map.get(c, c) for c in scene[\"characters_in_scene\"]]\n",
        "\n",
        "# Replace characters list with English-mapped ones (if needed)\n",
        "data[\"characters\"] = [character_map.get(c, c) for c in data[\"characters\"]]\n",
        "\n",
        "# Save the updated file\n",
        "with open(\"english.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"✅ Character mapping done and saved to 'english.json'\")\n"
      ],
      "metadata": {
        "id": "uv1BFpjOZQSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    output_dir = \"./panels/\"\n",
        "    json_file = \"english.json\"\n",
        "\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Cache to avoid reloading models\n",
        "pipe_cache = {}\n",
        "\n",
        "def load_model_for_inference(character):\n",
        "    \"\"\"Load and cache model for a specific character using LoRA.\"\"\"\n",
        "    if character in pipe_cache:\n",
        "        return pipe_cache[character]\n",
        "\n",
        "    print(f\"🧠 Loading model for {character}\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(Config.base_model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "    lora_path = os.path.join(Config.lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "    if os.path.exists(lora_path):\n",
        "        print(f\"🔗 Applying LoRA for {character} from {lora_path}\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path).merge_and_unload()\n",
        "    else:\n",
        "        print(f\"⚠️ No LoRA found for {character}, using base model.\")\n",
        "\n",
        "    pipe_cache[character] = pipe\n",
        "    return pipe\n",
        "\n",
        "def generate_comic_from_json(json_file):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    last_location = None\n",
        "\n",
        "    for scene in data[\"scenes\"]:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "        location = scene.get(\"location\") or last_location or \"Unknown Place\"\n",
        "        last_location = location\n",
        "\n",
        "        # Choose character\n",
        "        if scene[\"dialogues\"]:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "        else:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "\n",
        "        # Build prompt\n",
        "        if location.lower() not in scene_text.lower():\n",
        "            scene_text = f\"In the {location}, {scene_text}\"\n",
        "        prompt = (\n",
        "            f\"{scene_text}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, graphic novel style.\"\n",
        "        )\n",
        "\n",
        "        # Load model\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            pipe = load_model_for_inference(character)\n",
        "\n",
        "            print(f\"🎨 Scene {scene_number}: Prompt -> {prompt}\")\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                image = pipe(prompt).images[0]\n",
        "\n",
        "            output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "            image.save(output_path)\n",
        "            print(f\"✅ Saved panel at {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating scene {scene_number}: {e}\")\n",
        "\n",
        "    print(\"✅✅ Comic generation complete!\")\n",
        "\n",
        "# ✅ Run\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)'''\n"
      ],
      "metadata": {
        "id": "EHR_48F0c5aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    output_dir = \"./panels/\"\n",
        "    json_file = \"english.json\"\n",
        "\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Character descriptions (used in prompt for better generation)\n",
        "character_descriptions = {\n",
        "    \"Bruno\": \"a playful brown dog with a wagging tail\",\n",
        "    \"Tina\": \"a cheerful girl with braided hair and bright eyes\",\n",
        "    \"Ram\": \"a handsome boy with traditional clothes and a gentle smile\"\n",
        "}\n",
        "\n",
        "# ✅ Cache for model pipes\n",
        "pipe_cache = {}\n",
        "\n",
        "def load_model_for_inference(character):\n",
        "    \"\"\"Load and cache model for a specific character using LoRA.\"\"\"\n",
        "    if character in pipe_cache:\n",
        "        return pipe_cache[character]\n",
        "\n",
        "    print(f\"🧠 Loading model for {character}\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(Config.base_model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "    lora_path = os.path.join(Config.lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "    if os.path.exists(lora_path):\n",
        "        print(f\"🔗 Applying LoRA for {character} from {lora_path}\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path).merge_and_unload()\n",
        "    else:\n",
        "        print(f\"⚠️ No LoRA found for {character}, using base model.\")\n",
        "\n",
        "    pipe_cache[character] = pipe\n",
        "    return pipe\n",
        "\n",
        "def generate_comic_from_json(json_file):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    last_location = None\n",
        "\n",
        "    for scene in data[\"scenes\"]:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "        location = scene.get(\"location\") or last_location or \"Unknown Place\"\n",
        "        last_location = location\n",
        "\n",
        "        # Choose a character (dialogue character or first visible one)\n",
        "        if scene[\"dialogues\"]:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "        else:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "\n",
        "        # ✅ Get character description\n",
        "        char_desc = character_descriptions.get(character, character)\n",
        "\n",
        "        # ✅ Update scene text with character description and location if needed\n",
        "        if location.lower() not in scene_text.lower():\n",
        "            scene_text = f\"In the {location}, {char_desc} is present. {scene_text}\"\n",
        "\n",
        "        # ✅ Final prompt\n",
        "        prompt = (\n",
        "            f\"{scene_text}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, graphic novel style.\"\n",
        "        )\n",
        "\n",
        "        # ✅ Load model and generate image\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            pipe = load_model_for_inference(character)\n",
        "\n",
        "            print(f\"🎨 Scene {scene_number}: Prompt -> {prompt}\")\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                image = pipe(prompt).images[0]\n",
        "\n",
        "            output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "            image.save(output_path)\n",
        "            print(f\"✅ Saved panel at {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating scene {scene_number}: {e}\")\n",
        "\n",
        "    print(\"✅✅ Comic generation complete!\")\n",
        "\n",
        "# ✅ Run\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)'''\n"
      ],
      "metadata": {
        "id": "ZAdOESJZd8Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    output_dir = \"./panels/\"\n",
        "    json_file = \"english.json\"\n",
        "\n",
        "# ✅ Create output folder\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Style prompts based on known visual references\n",
        "character_prompts = {\n",
        "    \"Ram\": \"a charming young man with a blonde hair and blue eyes, inspired by Flynn Rider from Tangled, Disney-style\",\n",
        "    \"Bruno\": \"a goofy, friendly Great Dane dog, specifically a cartoon dog like Scooby-Doo\",\n",
        "    \"Tina\": \"a brave island girl with long curly black hair and tropical attire, inspired by Moana, Disney-style\"\n",
        "}\n",
        "\n",
        "# ✅ Cache for reusing loaded models\n",
        "pipe_cache = {}\n",
        "\n",
        "def load_model_for_inference(character):\n",
        "    \"\"\"Load and cache model for a specific character using LoRA.\"\"\"\n",
        "    if character in pipe_cache:\n",
        "        return pipe_cache[character]\n",
        "\n",
        "    print(f\"🧠 Loading model for {character}\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        Config.base_model, torch_dtype=torch.float16\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    lora_path = os.path.join(Config.lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "    if os.path.exists(lora_path):\n",
        "        print(f\"🔗 Applying LoRA for {character} from {lora_path}\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path).merge_and_unload()\n",
        "    else:\n",
        "        print(f\"⚠️ No LoRA found for {character}, using base model.\")\n",
        "\n",
        "    pipe_cache[character] = pipe\n",
        "    return pipe\n",
        "\n",
        "def generate_comic_from_json(json_file):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    last_location = None\n",
        "\n",
        "    for scene in data[\"scenes\"]:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "        location = scene.get(\"location\") or last_location or \"Unknown Place\"\n",
        "        last_location = location\n",
        "\n",
        "        # Determine main character for the scene\n",
        "        character = (\n",
        "            scene[\"characters_in_scene\"][0]\n",
        "            if scene[\"characters_in_scene\"]\n",
        "            else data[\"characters\"][0]\n",
        "        )\n",
        "\n",
        "        # Add location context if needed\n",
        "        if location.lower() not in scene_text.lower():\n",
        "            scene_text = f\"In the {location}, {scene_text}\"\n",
        "\n",
        "        # Add style description\n",
        "        style_desc = character_prompts.get(character, \"\")\n",
        "        prompt = (\n",
        "            f\"{scene_text}. {style_desc}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, graphic novel style.\"\n",
        "        )\n",
        "\n",
        "        # Load LoRA model\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            pipe = load_model_for_inference(character)\n",
        "\n",
        "            print(f\"🎨 Scene {scene_number}: Prompt -> {prompt}\")\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                image = pipe(prompt).images[0]\n",
        "\n",
        "            output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "            image.save(output_path)\n",
        "            print(f\"✅ Saved panel at {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating scene {scene_number}: {e}\")\n",
        "\n",
        "    print(\"✅✅ Comic generation complete!\")\n",
        "\n",
        "# ✅ Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)\n"
      ],
      "metadata": {
        "id": "0LmDhnHofsiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Noto Sans Devanagari\n",
        "!apt-get install -y fonts-noto\n"
      ],
      "metadata": {
        "id": "SfOucSOWkNgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import json\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    json_path = \"hindi_story.json\"\n",
        "    panels_dir = \"/content/panels\"\n",
        "    font_path = \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf\"\n",
        "    font_size = 36\n",
        "    output_dir = \"/content/panels_with_dialogue\"\n",
        "\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Load font\n",
        "try:\n",
        "    font = ImageFont.truetype(Config.font_path, Config.font_size)\n",
        "except OSError:\n",
        "    raise RuntimeError(f\"Could not load font from: {Config.font_path}\")\n",
        "\n",
        "# ✅ Load story JSON\n",
        "with open(Config.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ✅ Add dialogues to each panel with background boxes\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene_number = scene[\"scene_number\"]\n",
        "    dialogues = scene.get(\"dialogues\", [])\n",
        "\n",
        "    if not dialogues:\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(Config.panels_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"⚠️ Scene {scene_number}: No matching image found.\")\n",
        "        continue\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Starting position\n",
        "    x, y = 50, 50\n",
        "    line_height = Config.font_size + 30\n",
        "    padding = 15\n",
        "\n",
        "    for dialogue in dialogues:\n",
        "        # Get text bounding box\n",
        "        bbox = draw.textbbox((x, y), dialogue, font=font)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "\n",
        "        # Draw white rectangle background with black border\n",
        "        box_coords = [x - padding, y - padding, x + text_width + padding, y + text_height + padding]\n",
        "        draw.rectangle(box_coords, fill=\"white\", outline=\"black\", width=2)\n",
        "\n",
        "        # Draw the dialogue text\n",
        "        draw.text((x, y), dialogue, font=font, fill=\"black\")\n",
        "\n",
        "        # Move to next line\n",
        "        y += line_height\n",
        "\n",
        "    output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    image.save(output_path)\n",
        "    print(f\"💬 Scene {scene_number}: Dialogue box added -> Saved to {output_path}\")\n",
        "\n",
        "print(\"🎉 All dialogues added with background boxes!\")'''\n"
      ],
      "metadata": {
        "id": "9-uHEbCajt1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    json_path = \"hindi_story.json\"\n",
        "    panels_dir = \"/content/panels\"\n",
        "    font_path = \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf\"\n",
        "    font_size = 36\n",
        "    output_dir_with_dialogue = \"/content/panels_with_dialogue\"\n",
        "    output_dir_without_dialogue = \"/content/panels_without_dialogue\"\n",
        "\n",
        "# ✅ Create output directories\n",
        "os.makedirs(Config.output_dir_with_dialogue, exist_ok=True)\n",
        "os.makedirs(Config.output_dir_without_dialogue, exist_ok=True)\n",
        "\n",
        "# ✅ Load font\n",
        "try:\n",
        "    font = ImageFont.truetype(Config.font_path, Config.font_size)\n",
        "except OSError:\n",
        "    raise RuntimeError(f\"Could not load font from: {Config.font_path}\")\n",
        "\n",
        "# ✅ Load story JSON\n",
        "with open(Config.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ✅ Process each scene\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene_number = scene[\"scene_number\"]\n",
        "    dialogues = scene.get(\"dialogues\", [])\n",
        "\n",
        "    image_path = os.path.join(Config.panels_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"⚠️ Scene {scene_number}: No matching image found.\")\n",
        "        continue\n",
        "\n",
        "    # ✅ Save the original image as \"without dialogue\"\n",
        "    image = Image.open(image_path)\n",
        "    no_dialogue_path = os.path.join(Config.output_dir_without_dialogue, f\"comic_panel_{scene_number}.bmp\")\n",
        "    image.save(no_dialogue_path)\n",
        "    print(f\"📁 Scene {scene_number}: Saved without dialogue to -> {no_dialogue_path}\")\n",
        "\n",
        "    # ✅ If no dialogues, skip creating a second version\n",
        "    if not dialogues:\n",
        "        continue\n",
        "\n",
        "    # ✅ Create copy for dialogue version\n",
        "    image_with_dialogue = image.copy()\n",
        "    draw = ImageDraw.Draw(image_with_dialogue)\n",
        "\n",
        "    x, y = 50, 50\n",
        "    line_height = Config.font_size + 30\n",
        "    padding = 15\n",
        "\n",
        "    for dialogue in dialogues:\n",
        "        bbox = draw.textbbox((x, y), dialogue, font=font)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "\n",
        "        # White bubble with black outline\n",
        "        box_coords = [x - padding, y - padding, x + text_width + padding, y + text_height + padding]\n",
        "        draw.rectangle(box_coords, fill=\"white\", outline=\"black\", width=2)\n",
        "\n",
        "        draw.text((x, y), dialogue, font=font, fill=\"black\")\n",
        "        y += line_height\n",
        "\n",
        "    # ✅ Save dialogue image\n",
        "    dialogue_path = os.path.join(Config.output_dir_with_dialogue, f\"comic_panel_{scene_number}.bmp\")\n",
        "    image_with_dialogue.save(dialogue_path)\n",
        "    print(f\"💬 Scene {scene_number}: Dialogue version saved to -> {dialogue_path}\")\n",
        "\n",
        "print(\"✅✅ Done! All panels saved with and without dialogues.\")\n"
      ],
      "metadata": {
        "id": "nHp0h_hmlimz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ✅ Configuration\n",
        "class Config:\n",
        "    json_path = \"hindi_story.json\"\n",
        "    dialogue_dir = \"/content/panels_with_dialogue\"\n",
        "    no_dialogue_dir = \"/content/panels_without_dialogue\"\n",
        "    final_strip_path = \"/content/final_comic_strip.bmp\"\n",
        "    layout = \"horizontal\"  # or \"vertical\"\n",
        "\n",
        "# ✅ Load JSON\n",
        "with open(Config.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ✅ Gather all scene images in order\n",
        "scene_images = []\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene_number = scene[\"scene_number\"]\n",
        "    has_dialogue = bool(scene.get(\"dialogues\"))\n",
        "\n",
        "    # Pick correct image based on presence of dialogues\n",
        "    if has_dialogue:\n",
        "        img_path = os.path.join(Config.dialogue_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    else:\n",
        "        img_path = os.path.join(Config.no_dialogue_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"⚠️ Image for scene {scene_number} not found at {img_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    image = Image.open(img_path)\n",
        "    scene_images.append(image)\n",
        "\n",
        "# ✅ Combine images\n",
        "if not scene_images:\n",
        "    raise RuntimeError(\"No images found to create comic strip.\")\n",
        "\n",
        "# Dimensions for final canvas\n",
        "if Config.layout == \"horizontal\":\n",
        "    total_width = sum(img.width for img in scene_images)\n",
        "    max_height = max(img.height for img in scene_images)\n",
        "    final_image = Image.new(\"RGB\", (total_width, max_height), color=(255, 255, 255))\n",
        "\n",
        "    x_offset = 0\n",
        "    for img in scene_images:\n",
        "        final_image.paste(img, (x_offset, 0))\n",
        "        x_offset += img.width\n",
        "\n",
        "else:  # vertical layout\n",
        "    max_width = max(img.width for img in scene_images)\n",
        "    total_height = sum(img.height for img in scene_images)\n",
        "    final_image = Image.new(\"RGB\", (max_width, total_height), color=(255, 255, 255))\n",
        "\n",
        "    y_offset = 0\n",
        "    for img in scene_images:\n",
        "        final_image.paste(img, (0, y_offset))\n",
        "        y_offset += img.height\n",
        "\n",
        "# ✅ Save the final comic strip\n",
        "final_image.save(Config.final_strip_path)\n",
        "print(f\"🎉 Comic strip created: {Config.final_strip_path}\")\n"
      ],
      "metadata": {
        "id": "_XtX7WPDl18P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}