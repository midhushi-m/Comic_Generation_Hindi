{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8rUZRmLSceRYbS2tWSzNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midhushi-m/Comic_Generation_Hindi/blob/main/comic_generation_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Mount Google Drive\n",
        "\n",
        "# Change directory to your model folder\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/character\")\n"
      ],
      "metadata": {
        "id": "dNZfCnypncqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
      ],
      "metadata": {
        "id": "aoakVG5_6JiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import json\n",
        "import re\n",
        "\n",
        "def extract_characters(text):\n",
        "    # Simple pattern to catch names before verbs like '‡§ï‡§π‡§§‡§æ ‡§π‡•à', '‡§ï‡§π‡§§‡•Ä ‡§π‡•à'\n",
        "    name_pattern = r\"(\\w+)\\s+(‡§ï‡§π‡§§‡§æ ‡§π‡•à|‡§ï‡§π‡§§‡•Ä ‡§π‡•à|‡§¨‡•ã‡§≤‡§æ|‡§¨‡•ã‡§≤‡•Ä)\"\n",
        "    characters = set()\n",
        "\n",
        "    # Find all names before dialogue markers\n",
        "    for match in re.finditer(name_pattern, text):\n",
        "        characters.add(match.group(1))\n",
        "\n",
        "    # Additional manual patterns for this specific story\n",
        "    if \"‡§∞‡§æ‡§Æ\" in text:\n",
        "        characters.add(\"‡§∞‡§æ‡§Æ\")\n",
        "    if \"‡§ï‡§æ‡§≤‡•Ç\" in text:\n",
        "        characters.add(\"‡§ï‡§æ‡§≤‡•Ç\")\n",
        "    if \"‡§∏‡•ã‡§®‡•Ä\" in text:\n",
        "        characters.add(\"‡§∏‡•ã‡§®‡•Ä\")\n",
        "\n",
        "    return list(characters)\n",
        "\n",
        "def split_scenes(text):\n",
        "    sentences = [s.strip() + \"‡•§\" for s in text.split(\"‡•§\") if s.strip()]\n",
        "    scenes = []\n",
        "    all_characters = extract_characters(text)\n",
        "    current_location = \"‡§Ö‡§ú‡•ç‡§û‡§æ‡§§\"\n",
        "\n",
        "    for i, sentence in enumerate(sentences, 1):\n",
        "        # Update location\n",
        "        if \"‡§ú‡§Ç‡§ó‡§≤\" in sentence:\n",
        "            current_location = \"‡§ú‡§Ç‡§ó‡§≤\"\n",
        "        elif \"‡§ù‡•Ä‡§≤\" in sentence:\n",
        "            current_location = \"‡§ù‡•Ä‡§≤\"\n",
        "\n",
        "        # Characters in scene\n",
        "        chars_in_scene = [c for c in all_characters if c in sentence]\n",
        "        if \"‡§§‡•Ä‡§®‡•ã‡§Ç\" in sentence:\n",
        "            chars_in_scene = all_characters\n",
        "\n",
        "        # Detect dialogue between single quotes\n",
        "        dialogue = None\n",
        "        if \"'\" in sentence:\n",
        "            parts = sentence.split(\"'\")\n",
        "            if len(parts) >= 3:\n",
        "                dialogue_text = parts[1].strip(\"‡•§\")\n",
        "                speaker_match = re.search(r\"(\\w+)\\s+(?:‡§ï‡§π‡§§‡§æ ‡§π‡•à|‡§ï‡§π‡§§‡•Ä ‡§π‡•à|‡§¨‡•ã‡§≤‡§§‡§æ ‡§π‡•à|‡§¨‡•ã‡§≤‡§§‡•Ä ‡§π‡•à)\", sentence)\n",
        "                speaker = speaker_match.group(1) if speaker_match else \"unknown\"\n",
        "                dialogue = {\n",
        "                    \"character\": speaker,\n",
        "                    \"text\": dialogue_text,\n",
        "                    \"emotion\": detect_emotion(dialogue_text),\n",
        "                    \"position\": detect_position(sentence, speaker)\n",
        "                }\n",
        "\n",
        "\n",
        "        scene_data = {\n",
        "            \"scene_number\": i,\n",
        "            \"location\": current_location,\n",
        "            \"scene_text\": sentence,\n",
        "            \"characters_in_scene\": chars_in_scene,\n",
        "            \"emotion\": detect_scene_emotion(sentence),\n",
        "            \"position\": detect_scene_position(sentence),\n",
        "            \"dialogues\": [dialogue] if dialogue else []\n",
        "        }\n",
        "\n",
        "        scenes.append(scene_data)\n",
        "\n",
        "    return scenes\n",
        "\n",
        "# Helper functions for emotion and position detection\n",
        "def detect_emotion(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in [\"‡§ñ‡•Å‡§∂\", \"‡§π‡§Å‡§∏\", \"‡§Æ‡•Å‡§∏‡•ç‡§ï‡•Å‡§∞\"]):\n",
        "        return \"happy\"\n",
        "    elif any(word in text for word in [\"‡§°‡§∞\", \"‡§≠‡§Ø\"]):\n",
        "        return \"scared\"\n",
        "    elif any(word in text for word in [\"‡§¶‡•Å‡§ñ\", \"‡§â‡§¶‡§æ‡§∏\"]):\n",
        "        return \"sad\"\n",
        "    return \"smile\"  # Default\n",
        "\n",
        "def detect_position(sentence, character):\n",
        "    sentence = sentence.lower()\n",
        "    if \"‡§¨‡•à‡§†\" in sentence:\n",
        "        return \"sitting\"\n",
        "    elif \"‡§≤‡•á‡§ü\" in sentence:\n",
        "        return \"lying\"\n",
        "    elif \"‡§ö‡§≤\" in sentence:\n",
        "        return \"walking\"\n",
        "    return \"standing\"  # Default\n",
        "\n",
        "def detect_scene_emotion(sentence):\n",
        "    # Similar logic as detect_emotion but for whole scene\n",
        "    return detect_emotion(sentence)\n",
        "\n",
        "def detect_scene_position(sentence):\n",
        "    # Similar logic as detect_position but for whole scene\n",
        "    if \"‡§¨‡•à‡§†\" in sentence:\n",
        "        return \"sitting\"\n",
        "    return \"standing\"\n",
        "\n",
        "# Hindi story\n",
        "hindi_story = \"\"\"\n",
        "‡§∞‡§æ‡§Æ, ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§≤‡§°‡§º‡§ï‡§æ, ‡§ú‡§Ç‡§ó‡§≤ ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á ‡§ï‡§æ‡§≤‡•Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
        "‡§µ‡§π‡§æ‡§Å ‡§â‡§∏‡§ï‡•Ä ‡§Æ‡•Å‡§≤‡§æ‡§ï‡§æ‡§§ ‡§∏‡•ã‡§®‡•Ä ‡§®‡§æ‡§Æ ‡§ï‡•Ä ‡§è‡§ï ‡§≤‡§°‡§º‡§ï‡•Ä ‡§∏‡•á ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§ ‡§ï‡§æ‡§≤‡•Ç ‡§ï‡§π‡§§‡§æ ‡§π‡•à '‡§®‡§Æ‡§∏‡•ç‡§§‡•á'‡•§ ‡§∏‡•ã‡§®‡•Ä ‡§ï‡§π‡§§‡•Ä ‡§π‡•à '‡§π‡§æ‡§Ø'‡•§\n",
        "‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§§‡•Ä‡§®‡•ã‡§Ç ‡§è‡§ï ‡§ù‡•Ä‡§≤ ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§¨‡•à‡§†‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§æ‡§§‡•á‡§Ç ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
        "\"\"\"\n",
        "\n",
        "# Process the story\n",
        "characters = extract_characters(hindi_story)\n",
        "scenes = split_scenes(hindi_story)\n",
        "\n",
        "story_data = {\n",
        "    \"original_hindi\": hindi_story.strip(),\n",
        "    \"characters\": characters,\n",
        "    \"scenes\": scenes\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "with open(\"hindi_story_processed.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(story_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"‚úÖ Hindi story processed successfully!\")'''"
      ],
      "metadata": {
        "id": "MzeXr7PT6VYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def extract_characters(text):\n",
        "    name_pattern = r\"(\\w+)\\s+(‡§ï‡§π‡§§‡§æ ‡§π‡•à|‡§ï‡§π‡§§‡•Ä ‡§π‡•à|‡§¨‡•ã‡§≤‡§æ|‡§¨‡•ã‡§≤‡•Ä|‡§¨‡•ã‡§≤‡§§‡§æ ‡§π‡•à|‡§¨‡•ã‡§≤‡§§‡•Ä ‡§π‡•à)\"\n",
        "    characters = set()\n",
        "\n",
        "    for match in re.finditer(name_pattern, text):\n",
        "        characters.add(match.group(1))\n",
        "\n",
        "    # Additional manual patterns for this specific story\n",
        "    for name in [\"‡§∞‡§æ‡§Æ\", \"‡§ï‡§æ‡§≤‡•Ç\", \"‡§∏‡•ã‡§®‡•Ä\"]:\n",
        "        if name in text:\n",
        "            characters.add(name)\n",
        "\n",
        "    return list(characters)\n",
        "\n",
        "def split_scenes(text):\n",
        "    sentences = [s.strip() + \"‡•§\" for s in text.split(\"‡•§\") if s.strip()]\n",
        "    scenes = []\n",
        "    all_characters = extract_characters(text)\n",
        "    current_location = \"‡§Ö‡§ú‡•ç‡§û‡§æ‡§§\"\n",
        "\n",
        "    for i, sentence in enumerate(sentences, 1):\n",
        "        if \"‡§ú‡§Ç‡§ó‡§≤\" in sentence:\n",
        "            current_location = \"‡§ú‡§Ç‡§ó‡§≤\"\n",
        "        elif \"‡§ù‡•Ä‡§≤\" in sentence:\n",
        "            current_location = \"‡§ù‡•Ä‡§≤\"\n",
        "\n",
        "        chars_in_scene = [c for c in all_characters if c in sentence]\n",
        "        if \"‡§§‡•Ä‡§®‡•ã‡§Ç\" in sentence or \"‡§∏‡§≠‡•Ä\" in sentence:\n",
        "            chars_in_scene = all_characters\n",
        "\n",
        "        # Detect dialogue text inside single quotes\n",
        "        dialogues = []\n",
        "        matches = re.findall(r\"'(.*?)'\", sentence)\n",
        "        for d in matches:\n",
        "            dialogues.append(d.strip(\"‡•§\"))\n",
        "\n",
        "        scene_data = {\n",
        "            \"scene_number\": i,\n",
        "            \"location\": current_location,\n",
        "            \"scene_text\": sentence,\n",
        "            \"characters_in_scene\": chars_in_scene,\n",
        "            \"emotion\": detect_scene_emotion(sentence),\n",
        "            \"position\": detect_scene_position(sentence),\n",
        "            \"dialogues\": dialogues\n",
        "        }\n",
        "\n",
        "        scenes.append(scene_data)\n",
        "\n",
        "    return scenes\n",
        "\n",
        "def detect_emotion(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in [\"‡§ñ‡•Å‡§∂\", \"‡§π‡§Å‡§∏\", \"‡§Æ‡•Å‡§∏‡•ç‡§ï‡•Å‡§∞\"]):\n",
        "        return \"happy\"\n",
        "    elif any(word in text for word in [\"‡§°‡§∞\", \"‡§≠‡§Ø\"]):\n",
        "        return \"scared\"\n",
        "    elif any(word in text for word in [\"‡§¶‡•Å‡§ñ\", \"‡§â‡§¶‡§æ‡§∏\"]):\n",
        "        return \"sad\"\n",
        "    return \"smile\"\n",
        "\n",
        "def detect_position(sentence, character):\n",
        "    sentence = sentence.lower()\n",
        "    if \"‡§¨‡•à‡§†\" in sentence:\n",
        "        return \"sitting\"\n",
        "    elif \"‡§≤‡•á‡§ü\" in sentence:\n",
        "        return \"lying\"\n",
        "    elif \"‡§ö‡§≤\" in sentence:\n",
        "        return \"walking\"\n",
        "    return \"standing\"\n",
        "\n",
        "def detect_scene_emotion(sentence):\n",
        "    return detect_emotion(sentence)\n",
        "\n",
        "def detect_scene_position(sentence):\n",
        "    if \"‡§¨‡•à‡§†\" in sentence:\n",
        "        return \"sitting\"\n",
        "    return \"standing\"\n",
        "\n",
        "# Hindi story\n",
        "hindi_story = \"\"\"\n",
        "‡§∞‡§æ‡§Æ, ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§≤‡§°‡§º‡§ï‡§æ, ‡§ú‡§Ç‡§ó‡§≤ ‡§Æ‡•á‡§Ç ‡§Ö‡§™‡§®‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á ‡§ï‡§æ‡§≤‡•Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à‡•§\n",
        "‡§µ‡§π‡§æ‡§Å ‡§â‡§∏‡§ï‡•Ä ‡§Æ‡•Å‡§≤‡§æ‡§ï‡§æ‡§§ ‡§∏‡•ã‡§®‡•Ä ‡§®‡§æ‡§Æ ‡§ï‡•Ä ‡§è‡§ï ‡§≤‡§°‡§º‡§ï‡•Ä ‡§∏‡•á ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§ ‡§ï‡§æ‡§≤‡•Ç ‡§ï‡§π‡§§‡§æ ‡§π‡•à '‡§®‡§Æ‡§∏‡•ç‡§§‡•á'‡•§ ‡§∏‡•ã‡§®‡•Ä ‡§ï‡§π‡§§‡•Ä ‡§π‡•à '‡§π‡§æ‡§Ø'‡•§\n",
        "‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§§‡•Ä‡§®‡•ã‡§Ç ‡§è‡§ï ‡§ù‡•Ä‡§≤ ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§¨‡•à‡§†‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§¨‡§æ‡§§‡•á‡§Ç ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§\n",
        "\"\"\"\n",
        "\n",
        "characters = extract_characters(hindi_story)\n",
        "scenes = split_scenes(hindi_story)\n",
        "\n",
        "story_data = {\n",
        "    \"original_hindi\": hindi_story.strip(),\n",
        "    \"characters\": characters,\n",
        "    \"scenes\": scenes\n",
        "}\n",
        "\n",
        "with open(\"hindi_story.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(story_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"‚úÖ Hindi story processed successfully!\")\n"
      ],
      "metadata": {
        "id": "jZjUWucW_c6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate bitsandbytes xformers safetensors\n",
        "!pip install peft\n"
      ],
      "metadata": {
        "id": "5GeW1YDhB7yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.nn import functional as F\n",
        "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ‚úÖ Set Random Seeds for Reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    dataset_dir = \"/content/drive/MyDrive/character/train\"\n",
        "    output_dir = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    batch_size = 1\n",
        "    gradient_accumulation_steps = 4\n",
        "    learning_rate = 1e-5\n",
        "    num_epochs = 10\n",
        "    mixed_precision = \"fp16\"\n",
        "    lora_r = 16\n",
        "    lora_alpha = 32\n",
        "    lora_dropout = 0.1\n",
        "    target_modules = [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]\n",
        "    validation_steps = 100\n",
        "    characters = sorted(os.listdir(dataset_dir))  # Sort characters for consistent order\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# ‚úÖ Load Stable Diffusion Model\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    config.model_id, torch_dtype=torch.float16 if config.mixed_precision == \"fp16\" else torch.float32\n",
        ")\n",
        "pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# ‚úÖ Apply LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=config.lora_r,\n",
        "    lora_alpha=config.lora_alpha,\n",
        "    target_modules=config.target_modules,\n",
        "    lora_dropout=config.lora_dropout\n",
        ")\n",
        "pipe.unet = get_peft_model(pipe.unet, lora_config)\n",
        "pipe.unet.train()\n",
        "\n",
        "# ‚úÖ Define Data Augmentation & Custom Image Dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, character, transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, character)\n",
        "        self.character = character\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "        self.labels = []\n",
        "\n",
        "        for emotion in sorted(os.listdir(self.root_dir)):\n",
        "            emotion_path = os.path.join(self.root_dir, emotion)\n",
        "            if not os.path.isdir(emotion_path):  # ‚úÖ Skip files\n",
        "                continue\n",
        "\n",
        "            emotion_path = os.path.join(self.root_dir, emotion)\n",
        "            if not os.path.isdir(emotion_path):\n",
        "                continue\n",
        "\n",
        "            for file in os.listdir(emotion_path):\n",
        "                if file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                    self.image_files.append(os.path.join(emotion_path, file))\n",
        "                    self.labels.append(f\"{character}_{emotion}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        prompt = f\"A {label.split('_')[1]} {label.split('_')[0]} in comic style\"\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return {\"pixel_values\": image, \"prompt\": prompt}\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# ‚úÖ Training Loop for Each Character\n",
        "for character in config.characters:\n",
        "    print(f\"\\nüöÄ Training for character: {character}\")\n",
        "    char_dataset = ImageDataset(config.dataset_dir, character, transform=transform)\n",
        "    char_dataloader = DataLoader(char_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=config.learning_rate, weight_decay=0.01)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(char_dataloader) * config.num_epochs // config.gradient_accumulation_steps)\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        progress_bar = tqdm(total=len(char_dataloader), desc=f\"{character} - Epoch {epoch+1}\")\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for step, batch in enumerate(char_dataloader):\n",
        "            pixel_values = batch[\"pixel_values\"].to(\"cuda\").half()\n",
        "            latents = pipe.vae.encode(pixel_values).latent_dist.sample() * pipe.vae.config.scaling_factor\n",
        "            timesteps = torch.randint(0, pipe.scheduler.config.num_train_timesteps, (latents.shape[0],), device=\"cuda\").long()\n",
        "            noise = torch.randn_like(latents)\n",
        "            noisy_latents = pipe.scheduler.add_noise(latents, noise, timesteps)\n",
        "            text_input = pipe.tokenizer(batch[\"prompt\"], padding=\"max_length\", max_length=pipe.tokenizer.model_max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "            encoder_hidden_states = pipe.text_encoder(**text_input).last_hidden_state\n",
        "            model_pred = pipe.unet(noisy_latents, timesteps, encoder_hidden_states=encoder_hidden_states).sample\n",
        "            loss = F.mse_loss(model_pred, noise) / config.gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(pipe.unet.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "        progress_bar.close()\n",
        "\n",
        "    # ‚úÖ Save Checkpoint for Each Character\n",
        "    char_save_dir = os.path.join(config.output_dir, f\"{character}_lora\")\n",
        "    os.makedirs(char_save_dir, exist_ok=True)\n",
        "    lora_save_dir = os.path.join(char_save_dir, \"lora_adapter\")\n",
        "    pipe.unet.save_pretrained(lora_save_dir)\n",
        "    print(f\"‚úÖ LoRA model saved for {character} at {char_save_dir}\")\n",
        "\n",
        "print(\"üéâ Training Completed for All Characters!\")\n"
      ],
      "metadata": {
        "id": "Seod4FxpCGre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ‚úÖ Load Model for Inference with LoRA for a specific character\n",
        "def load_model_for_inference(base_model_path, lora_weights_path, character):\n",
        "    \"\"\"Loads the base Stable Diffusion model and applies LoRA weights for the specific character.\"\"\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(base_model_path, torch_dtype=torch.float16)\n",
        "    pipe.to(\"cuda\")\n",
        "\n",
        "    # ‚úÖ Define the correct path for LoRA adapter based on character\n",
        "    lora_adapter_path = os.path.join(lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "\n",
        "    # ‚úÖ Print the path for verification\n",
        "    print(f\"üîç Checking LoRA adapter path: {lora_adapter_path}\")\n",
        "\n",
        "    # ‚úÖ Check if the LoRA adapter exists and load it\n",
        "    if os.path.exists(lora_adapter_path):\n",
        "        print(f\"‚úÖ Loading LoRA adapter for {character} from {lora_adapter_path}...\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_adapter_path)\n",
        "        pipe.unet = pipe.unet.merge_and_unload()\n",
        "        print(f\"‚úÖ LoRA successfully merged for {character}.\")\n",
        "    else:\n",
        "        print(f\"‚ùå LoRA adapter for {character} not found at {lora_adapter_path}.\")\n",
        "\n",
        "    return pipe\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"  # Base model for Stable Diffusion\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"  # Correct path where LoRA weights are saved\n",
        "    output_dir = \"./panels/\"  # Folder to save the generated comic panels\n",
        "    json_file = \"hindi_story.json\"  # Input JSON file for comic generation\n",
        "\n",
        "# ‚úÖ Ensure output directory exists\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Generate image for each scene based on the character-specific model\n",
        "def generate_comic_from_json(json_file):\n",
        "    \"\"\"Reads a JSON file and generates comic panels for each scene based on character-specific models.\"\"\"\n",
        "\n",
        "    # ‚úÖ Load JSON data\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    scenes = data[\"scenes\"]\n",
        "    location = \"\"  # Keep track of the location\n",
        "\n",
        "    # ‚úÖ Generate panels for each scene\n",
        "    for scene in scenes:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "\n",
        "        # ‚úÖ Check if dialogues exist and are in the correct format\n",
        "        if scene.get(\"dialogues\"):\n",
        "            if isinstance(scene[\"dialogues\"], list):\n",
        "                # If dialogues are a list of strings, use the first one for dialogue_text\n",
        "                dialogue_text = scene[\"dialogues\"][0] if scene[\"dialogues\"] else \"No dialogue found\"\n",
        "                character = \"default_character\"  # Use a default character if not available\n",
        "            else:\n",
        "                # If dialogues are in a dictionary format, extract character and text\n",
        "                character = scene[\"dialogues\"].get(\"character\", \"default_character\")\n",
        "                dialogue_text = scene[\"dialogues\"].get(\"text\", \"No dialogue found\")\n",
        "        else:\n",
        "            # If no dialogues found, use a default character and dialogue\n",
        "            character = \"default_character\"\n",
        "            dialogue_text = \"No dialogue found\"\n",
        "\n",
        "        # ‚úÖ If location is not specified, use the last known location\n",
        "        if 'location' in scene and scene['location']:\n",
        "            location = scene['location']\n",
        "\n",
        "        if location:\n",
        "            # Add location to scene_text if not already part of it\n",
        "            if location.lower() not in scene_text.lower():\n",
        "                scene_text = f\"In the {location}, {scene_text}\"\n",
        "\n",
        "        # ‚úÖ Load the character-specific model for inference\n",
        "        inference_pipe = load_model_for_inference(Config.base_model, Config.lora_weights_path, character)\n",
        "\n",
        "        # ‚úÖ Add comic-style details to the prompt using scene_text and dialogue_text\n",
        "        prompt = (\n",
        "            f\"{scene_text}, with dialogue: '{dialogue_text}', highly detailed comic-style illustration, \"\n",
        "            \"vibrant colors, inked outlines, dynamic composition, expressive characters, in the style of graphic novels.\"\n",
        "        )\n",
        "\n",
        "        print(f\"üé® Generating panel for Scene {scene_number} with character {character}: {prompt}\")\n",
        "\n",
        "        # ‚úÖ Clear VRAM before generating\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # ‚úÖ Generate image\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            image = inference_pipe(prompt).images[0]\n",
        "\n",
        "        # ‚úÖ Save the image in BMP format\n",
        "        output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "        image.save(output_path)\n",
        "        print(f\"‚úÖ Panel {scene_number} for {character} saved: {output_path}\")\n",
        "\n",
        "    print(\"üéâ All comic panels generated successfully!\")\n",
        "\n",
        "# ‚úÖ Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)\n"
      ],
      "metadata": {
        "id": "PS15hnlFGwWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ‚úÖ Load Model for Inference with LoRA for a specific character\n",
        "def load_model_for_inference(base_model_path, lora_weights_path, character):\n",
        "    \"\"\"Loads the base Stable Diffusion model and applies LoRA weights for the specific character.\"\"\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(base_model_path, torch_dtype=torch.float16)\n",
        "    pipe.to(\"cuda\")\n",
        "\n",
        "    # ‚úÖ Define the correct path for LoRA adapter based on character\n",
        "    lora_adapter_path = os.path.join(lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "\n",
        "    # ‚úÖ Print the path for verification\n",
        "    print(f\"üîç Checking LoRA adapter path: {lora_adapter_path}\")\n",
        "\n",
        "    # ‚úÖ Check if the LoRA adapter exists and load it\n",
        "    if os.path.exists(lora_adapter_path):\n",
        "        print(f\"‚úÖ Loading LoRA adapter for {character} from {lora_adapter_path}...\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_adapter_path)\n",
        "        pipe.unet = pipe.unet.merge_and_unload()\n",
        "        print(f\"‚úÖ LoRA successfully merged for {character}.\")\n",
        "    else:\n",
        "        print(f\"‚ùå LoRA adapter for {character} not found at {lora_adapter_path}.\")\n",
        "\n",
        "    return pipe\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"  # Base model for Stable Diffusion\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"  # Correct path where LoRA weights are saved\n",
        "    output_dir = \"./panels/\"  # Folder to save the generated comic panels\n",
        "    json_file = \"hindi_story.json\"  # Input JSON file for comic generation\n",
        "\n",
        "# ‚úÖ Ensure output directory exists\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Generate image for each scene based on the character-specific model\n",
        "def generate_comic_from_json(json_file):\n",
        "    \"\"\"Reads a JSON file and generates comic panels for each scene based on character-specific models.\"\"\"\n",
        "\n",
        "    # ‚úÖ Load JSON data\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    scenes = data[\"scenes\"]\n",
        "    location = \"\"  # Keep track of the location\n",
        "\n",
        "    # ‚úÖ Define Hindi-to-English character mapping for LoRA\n",
        "    character_map = {\n",
        "        \"‡§∞‡§æ‡§Æ\": \"Ram\",\n",
        "        \"‡§ï‡§æ‡§≤‡•Ç\": \"Bruno\",\n",
        "        \"‡§∏‡•ã‡§®‡•Ä\": \"Tina\"\n",
        "    }\n",
        "\n",
        "    # ‚úÖ Generate panels for each scene\n",
        "    for scene in scenes:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "\n",
        "        # ‚úÖ Check if dialogues exist, and get the character if dialogues are present\n",
        "        if scene[\"dialogues\"]:\n",
        "            # If dialogue is just a list, assume one character is speaking\n",
        "            if isinstance(scene[\"dialogues\"][0], dict) and \"character\" in scene[\"dialogues\"][0]:\n",
        "                character = scene[\"dialogues\"][0][\"character\"]\n",
        "            else:\n",
        "                character = scene[\"characters_in_scene\"][0]\n",
        "        else:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else \"default_character\"\n",
        "            print(f\"‚ö†Ô∏è No dialogues found. Using default character: {character}\")\n",
        "\n",
        "        # ‚úÖ If location is not specified, use the last known location\n",
        "        if 'location' in scene and scene['location']:\n",
        "            location = scene['location']\n",
        "\n",
        "        if location:\n",
        "            # Add location to scene_text if not already part of it\n",
        "            if location.lower() not in scene_text.lower():\n",
        "                scene_text = f\"In the {location}, {scene_text}\"\n",
        "\n",
        "        # ‚úÖ Map Hindi character to English LoRA folder name\n",
        "        mapped_character = character_map.get(character, character)\n",
        "\n",
        "        # ‚úÖ Load the character-specific model for inference\n",
        "        inference_pipe = load_model_for_inference(Config.base_model, Config.lora_weights_path, mapped_character)\n",
        "\n",
        "        # ‚úÖ Add comic-style details to the prompt\n",
        "        prompt = (\n",
        "            f\"{scene_text}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, in the style of graphic novels.\"\n",
        "        )\n",
        "\n",
        "        print(f\"üé® Generating panel for Scene {scene_number} with character {character}: {prompt}\")\n",
        "\n",
        "        # ‚úÖ Clear VRAM before generating\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # ‚úÖ Generate image\n",
        "        with torch.autocast(\"cuda\"):\n",
        "            image = inference_pipe(prompt).images[0]\n",
        "\n",
        "        # ‚úÖ Save the image in BMP format\n",
        "        output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "        image.save(output_path)\n",
        "        print(f\"‚úÖ Panel {scene_number} for {character} saved: {output_path}\")\n",
        "\n",
        "    print(\"üéâ All comic panels generated successfully!\")\n",
        "\n",
        "# ‚úÖ Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)\n"
      ],
      "metadata": {
        "id": "B-PzFCKwKUnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "id": "w5ai-IVBQmkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from googletrans import Translator\n",
        "\n",
        "def translate_story(input_file, output_file):\n",
        "    # Initialize translator\n",
        "    translator = Translator()\n",
        "\n",
        "    # Load Hindi story\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        hindi_data = json.load(f)\n",
        "\n",
        "    # Translate the main story text\n",
        "    translated_story = translator.translate(hindi_data['original_hindi'], src='hi', dest='en').text\n",
        "\n",
        "    # Prepare English data structure\n",
        "    english_data = {\n",
        "        \"original_english\": translated_story,\n",
        "        \"characters\": [],\n",
        "        \"scenes\": []\n",
        "    }\n",
        "\n",
        "    # Translate character names (we'll keep these as is for LoRA mapping)\n",
        "    english_data['characters'] = hindi_data['characters']\n",
        "\n",
        "    # Translate each scene\n",
        "    for scene in hindi_data['scenes']:\n",
        "        translated_scene = {\n",
        "            \"scene_number\": scene[\"scene_number\"],\n",
        "            \"location\": translator.translate(scene[\"location\"], src='hi', dest='en').text,\n",
        "            \"scene_text\": translator.translate(scene[\"scene_text\"], src='hi', dest='en').text,\n",
        "            \"characters_in_scene\": scene[\"characters_in_scene\"],  # Keep original for mapping\n",
        "            \"emotion\": scene[\"emotion\"],  # Already in English\n",
        "            \"position\": scene[\"position\"],  # Already in English\n",
        "            \"dialogues\": [translator.translate(d, src='hi', dest='en').text for d in scene[\"dialogues\"]]\n",
        "        }\n",
        "        english_data['scenes'].append(translated_scene)\n",
        "\n",
        "    # Save translated story\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(english_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"‚úÖ Successfully translated {input_file} to {output_file}\")\n",
        "\n",
        "# Usage\n",
        "translate_story(\"hindi_story.json\", \"translated_story.json\")"
      ],
      "metadata": {
        "id": "O0tBkWdZXV-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJI0g-B3cVvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Your Hindi to English character mapping\n",
        "character_map = {\n",
        "    \"‡§ï‡§æ‡§≤‡•Ç\": \"Bruno\",\n",
        "    \"‡§∏‡•ã‡§®‡•Ä\": \"Tina\",\n",
        "    \"‡§∞‡§æ‡§Æ\": \"Ram\"\n",
        "}\n",
        "\n",
        "# Optional: LoRA adapter mapping (if needed later)\n",
        "lora_model_map = {\n",
        "    \"Kalu\": \"Bruno\",\n",
        "    \"Soni\": \"Tina\",\n",
        "    \"Ram\": \"Ram\"\n",
        "}\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"translated_story.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Update character names in each scene\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene[\"characters_in_scene\"] = [character_map.get(c, c) for c in scene[\"characters_in_scene\"]]\n",
        "\n",
        "# Replace characters list with English-mapped ones (if needed)\n",
        "data[\"characters\"] = [character_map.get(c, c) for c in data[\"characters\"]]\n",
        "\n",
        "# Save the updated file\n",
        "with open(\"english.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"‚úÖ Character mapping done and saved to 'english.json'\")\n"
      ],
      "metadata": {
        "id": "uv1BFpjOZQSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    output_dir = \"./panels/\"\n",
        "    json_file = \"english.json\"\n",
        "\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Cache to avoid reloading models\n",
        "pipe_cache = {}\n",
        "\n",
        "def load_model_for_inference(character):\n",
        "    \"\"\"Load and cache model for a specific character using LoRA.\"\"\"\n",
        "    if character in pipe_cache:\n",
        "        return pipe_cache[character]\n",
        "\n",
        "    print(f\"üß† Loading model for {character}\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(Config.base_model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "    lora_path = os.path.join(Config.lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "    if os.path.exists(lora_path):\n",
        "        print(f\"üîó Applying LoRA for {character} from {lora_path}\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path).merge_and_unload()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No LoRA found for {character}, using base model.\")\n",
        "\n",
        "    pipe_cache[character] = pipe\n",
        "    return pipe\n",
        "\n",
        "def generate_comic_from_json(json_file):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    last_location = None\n",
        "\n",
        "    for scene in data[\"scenes\"]:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "        location = scene.get(\"location\") or last_location or \"Unknown Place\"\n",
        "        last_location = location\n",
        "\n",
        "        # Choose character\n",
        "        if scene[\"dialogues\"]:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "        else:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "\n",
        "        # Build prompt\n",
        "        if location.lower() not in scene_text.lower():\n",
        "            scene_text = f\"In the {location}, {scene_text}\"\n",
        "        prompt = (\n",
        "            f\"{scene_text}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, graphic novel style.\"\n",
        "        )\n",
        "\n",
        "        # Load model\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            pipe = load_model_for_inference(character)\n",
        "\n",
        "            print(f\"üé® Scene {scene_number}: Prompt -> {prompt}\")\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                image = pipe(prompt).images[0]\n",
        "\n",
        "            output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "            image.save(output_path)\n",
        "            print(f\"‚úÖ Saved panel at {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error generating scene {scene_number}: {e}\")\n",
        "\n",
        "    print(\"‚úÖ‚úÖ Comic generation complete!\")\n",
        "\n",
        "# ‚úÖ Run\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)'''\n"
      ],
      "metadata": {
        "id": "EHR_48F0c5aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    output_dir = \"./panels/\"\n",
        "    json_file = \"english.json\"\n",
        "\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Character descriptions (used in prompt for better generation)\n",
        "character_descriptions = {\n",
        "    \"Bruno\": \"a playful brown dog with a wagging tail\",\n",
        "    \"Tina\": \"a cheerful girl with braided hair and bright eyes\",\n",
        "    \"Ram\": \"a handsome boy with traditional clothes and a gentle smile\"\n",
        "}\n",
        "\n",
        "# ‚úÖ Cache for model pipes\n",
        "pipe_cache = {}\n",
        "\n",
        "def load_model_for_inference(character):\n",
        "    \"\"\"Load and cache model for a specific character using LoRA.\"\"\"\n",
        "    if character in pipe_cache:\n",
        "        return pipe_cache[character]\n",
        "\n",
        "    print(f\"üß† Loading model for {character}\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(Config.base_model, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "    lora_path = os.path.join(Config.lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "    if os.path.exists(lora_path):\n",
        "        print(f\"üîó Applying LoRA for {character} from {lora_path}\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path).merge_and_unload()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No LoRA found for {character}, using base model.\")\n",
        "\n",
        "    pipe_cache[character] = pipe\n",
        "    return pipe\n",
        "\n",
        "def generate_comic_from_json(json_file):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    last_location = None\n",
        "\n",
        "    for scene in data[\"scenes\"]:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "        location = scene.get(\"location\") or last_location or \"Unknown Place\"\n",
        "        last_location = location\n",
        "\n",
        "        # Choose a character (dialogue character or first visible one)\n",
        "        if scene[\"dialogues\"]:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "        else:\n",
        "            character = scene[\"characters_in_scene\"][0] if scene[\"characters_in_scene\"] else data[\"characters\"][0]\n",
        "\n",
        "        # ‚úÖ Get character description\n",
        "        char_desc = character_descriptions.get(character, character)\n",
        "\n",
        "        # ‚úÖ Update scene text with character description and location if needed\n",
        "        if location.lower() not in scene_text.lower():\n",
        "            scene_text = f\"In the {location}, {char_desc} is present. {scene_text}\"\n",
        "\n",
        "        # ‚úÖ Final prompt\n",
        "        prompt = (\n",
        "            f\"{scene_text}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, graphic novel style.\"\n",
        "        )\n",
        "\n",
        "        # ‚úÖ Load model and generate image\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            pipe = load_model_for_inference(character)\n",
        "\n",
        "            print(f\"üé® Scene {scene_number}: Prompt -> {prompt}\")\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                image = pipe(prompt).images[0]\n",
        "\n",
        "            output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}_{character}.bmp\")\n",
        "            image.save(output_path)\n",
        "            print(f\"‚úÖ Saved panel at {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error generating scene {scene_number}: {e}\")\n",
        "\n",
        "    print(\"‚úÖ‚úÖ Comic generation complete!\")\n",
        "\n",
        "# ‚úÖ Run\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)'''\n"
      ],
      "metadata": {
        "id": "ZAdOESJZd8Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from peft import PeftModel\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    base_model = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    lora_weights_path = \"/content/drive/MyDrive/lora_trained_model\"\n",
        "    output_dir = \"./panels/\"\n",
        "    json_file = \"english.json\"\n",
        "\n",
        "# ‚úÖ Create output folder\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Style prompts based on known visual references\n",
        "character_prompts = {\n",
        "    \"Ram\": \"a charming young man with a blonde hair and blue eyes, inspired by Flynn Rider from Tangled, Disney-style\",\n",
        "    \"Bruno\": \"a goofy, friendly Great Dane dog, specifically a cartoon dog like Scooby-Doo\",\n",
        "    \"Tina\": \"a brave island girl with long curly black hair and tropical attire, inspired by Moana, Disney-style\"\n",
        "}\n",
        "\n",
        "# ‚úÖ Cache for reusing loaded models\n",
        "pipe_cache = {}\n",
        "\n",
        "def load_model_for_inference(character):\n",
        "    \"\"\"Load and cache model for a specific character using LoRA.\"\"\"\n",
        "    if character in pipe_cache:\n",
        "        return pipe_cache[character]\n",
        "\n",
        "    print(f\"üß† Loading model for {character}\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        Config.base_model, torch_dtype=torch.float16\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    lora_path = os.path.join(Config.lora_weights_path, f\"{character}_lora\", \"lora_adapter\")\n",
        "    if os.path.exists(lora_path):\n",
        "        print(f\"üîó Applying LoRA for {character} from {lora_path}\")\n",
        "        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path).merge_and_unload()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No LoRA found for {character}, using base model.\")\n",
        "\n",
        "    pipe_cache[character] = pipe\n",
        "    return pipe\n",
        "\n",
        "def generate_comic_from_json(json_file):\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    last_location = None\n",
        "\n",
        "    for scene in data[\"scenes\"]:\n",
        "        scene_number = scene[\"scene_number\"]\n",
        "        scene_text = scene[\"scene_text\"]\n",
        "        location = scene.get(\"location\") or last_location or \"Unknown Place\"\n",
        "        last_location = location\n",
        "\n",
        "        # Determine main character for the scene\n",
        "        character = (\n",
        "            scene[\"characters_in_scene\"][0]\n",
        "            if scene[\"characters_in_scene\"]\n",
        "            else data[\"characters\"][0]\n",
        "        )\n",
        "\n",
        "        # Add location context if needed\n",
        "        if location.lower() not in scene_text.lower():\n",
        "            scene_text = f\"In the {location}, {scene_text}\"\n",
        "\n",
        "        # Add style description\n",
        "        style_desc = character_prompts.get(character, \"\")\n",
        "        prompt = (\n",
        "            f\"{scene_text}. {style_desc}, highly detailed comic-style illustration, vibrant colors, \"\n",
        "            \"inked outlines, dynamic composition, expressive characters, graphic novel style.\"\n",
        "        )\n",
        "\n",
        "        # Load LoRA model\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            pipe = load_model_for_inference(character)\n",
        "\n",
        "            print(f\"üé® Scene {scene_number}: Prompt -> {prompt}\")\n",
        "            with torch.autocast(\"cuda\"):\n",
        "                image = pipe(prompt).images[0]\n",
        "\n",
        "            output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "            image.save(output_path)\n",
        "            print(f\"‚úÖ Saved panel at {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error generating scene {scene_number}: {e}\")\n",
        "\n",
        "    print(\"‚úÖ‚úÖ Comic generation complete!\")\n",
        "\n",
        "# ‚úÖ Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_comic_from_json(Config.json_file)\n"
      ],
      "metadata": {
        "id": "0LmDhnHofsiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Noto Sans Devanagari\n",
        "!apt-get install -y fonts-noto\n"
      ],
      "metadata": {
        "id": "SfOucSOWkNgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import json\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    json_path = \"hindi_story.json\"\n",
        "    panels_dir = \"/content/panels\"\n",
        "    font_path = \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf\"\n",
        "    font_size = 36\n",
        "    output_dir = \"/content/panels_with_dialogue\"\n",
        "\n",
        "os.makedirs(Config.output_dir, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Load font\n",
        "try:\n",
        "    font = ImageFont.truetype(Config.font_path, Config.font_size)\n",
        "except OSError:\n",
        "    raise RuntimeError(f\"Could not load font from: {Config.font_path}\")\n",
        "\n",
        "# ‚úÖ Load story JSON\n",
        "with open(Config.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ‚úÖ Add dialogues to each panel with background boxes\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene_number = scene[\"scene_number\"]\n",
        "    dialogues = scene.get(\"dialogues\", [])\n",
        "\n",
        "    if not dialogues:\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(Config.panels_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"‚ö†Ô∏è Scene {scene_number}: No matching image found.\")\n",
        "        continue\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Starting position\n",
        "    x, y = 50, 50\n",
        "    line_height = Config.font_size + 30\n",
        "    padding = 15\n",
        "\n",
        "    for dialogue in dialogues:\n",
        "        # Get text bounding box\n",
        "        bbox = draw.textbbox((x, y), dialogue, font=font)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "\n",
        "        # Draw white rectangle background with black border\n",
        "        box_coords = [x - padding, y - padding, x + text_width + padding, y + text_height + padding]\n",
        "        draw.rectangle(box_coords, fill=\"white\", outline=\"black\", width=2)\n",
        "\n",
        "        # Draw the dialogue text\n",
        "        draw.text((x, y), dialogue, font=font, fill=\"black\")\n",
        "\n",
        "        # Move to next line\n",
        "        y += line_height\n",
        "\n",
        "    output_path = os.path.join(Config.output_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    image.save(output_path)\n",
        "    print(f\"üí¨ Scene {scene_number}: Dialogue box added -> Saved to {output_path}\")\n",
        "\n",
        "print(\"üéâ All dialogues added with background boxes!\")'''\n"
      ],
      "metadata": {
        "id": "9-uHEbCajt1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    json_path = \"hindi_story.json\"\n",
        "    panels_dir = \"/content/panels\"\n",
        "    font_path = \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf\"\n",
        "    font_size = 36\n",
        "    output_dir_with_dialogue = \"/content/panels_with_dialogue\"\n",
        "    output_dir_without_dialogue = \"/content/panels_without_dialogue\"\n",
        "\n",
        "# ‚úÖ Create output directories\n",
        "os.makedirs(Config.output_dir_with_dialogue, exist_ok=True)\n",
        "os.makedirs(Config.output_dir_without_dialogue, exist_ok=True)\n",
        "\n",
        "# ‚úÖ Load font\n",
        "try:\n",
        "    font = ImageFont.truetype(Config.font_path, Config.font_size)\n",
        "except OSError:\n",
        "    raise RuntimeError(f\"Could not load font from: {Config.font_path}\")\n",
        "\n",
        "# ‚úÖ Load story JSON\n",
        "with open(Config.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ‚úÖ Process each scene\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene_number = scene[\"scene_number\"]\n",
        "    dialogues = scene.get(\"dialogues\", [])\n",
        "\n",
        "    image_path = os.path.join(Config.panels_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"‚ö†Ô∏è Scene {scene_number}: No matching image found.\")\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ Save the original image as \"without dialogue\"\n",
        "    image = Image.open(image_path)\n",
        "    no_dialogue_path = os.path.join(Config.output_dir_without_dialogue, f\"comic_panel_{scene_number}.bmp\")\n",
        "    image.save(no_dialogue_path)\n",
        "    print(f\"üìÅ Scene {scene_number}: Saved without dialogue to -> {no_dialogue_path}\")\n",
        "\n",
        "    # ‚úÖ If no dialogues, skip creating a second version\n",
        "    if not dialogues:\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ Create copy for dialogue version\n",
        "    image_with_dialogue = image.copy()\n",
        "    draw = ImageDraw.Draw(image_with_dialogue)\n",
        "\n",
        "    x, y = 50, 50\n",
        "    line_height = Config.font_size + 30\n",
        "    padding = 15\n",
        "\n",
        "    for dialogue in dialogues:\n",
        "        bbox = draw.textbbox((x, y), dialogue, font=font)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "\n",
        "        # White bubble with black outline\n",
        "        box_coords = [x - padding, y - padding, x + text_width + padding, y + text_height + padding]\n",
        "        draw.rectangle(box_coords, fill=\"white\", outline=\"black\", width=2)\n",
        "\n",
        "        draw.text((x, y), dialogue, font=font, fill=\"black\")\n",
        "        y += line_height\n",
        "\n",
        "    # ‚úÖ Save dialogue image\n",
        "    dialogue_path = os.path.join(Config.output_dir_with_dialogue, f\"comic_panel_{scene_number}.bmp\")\n",
        "    image_with_dialogue.save(dialogue_path)\n",
        "    print(f\"üí¨ Scene {scene_number}: Dialogue version saved to -> {dialogue_path}\")\n",
        "\n",
        "print(\"‚úÖ‚úÖ Done! All panels saved with and without dialogues.\")\n"
      ],
      "metadata": {
        "id": "nHp0h_hmlimz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ‚úÖ Configuration\n",
        "class Config:\n",
        "    json_path = \"hindi_story.json\"\n",
        "    dialogue_dir = \"/content/panels_with_dialogue\"\n",
        "    no_dialogue_dir = \"/content/panels_without_dialogue\"\n",
        "    final_strip_path = \"/content/final_comic_strip.bmp\"\n",
        "    layout = \"horizontal\"  # or \"vertical\"\n",
        "\n",
        "# ‚úÖ Load JSON\n",
        "with open(Config.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# ‚úÖ Gather all scene images in order\n",
        "scene_images = []\n",
        "for scene in data[\"scenes\"]:\n",
        "    scene_number = scene[\"scene_number\"]\n",
        "    has_dialogue = bool(scene.get(\"dialogues\"))\n",
        "\n",
        "    # Pick correct image based on presence of dialogues\n",
        "    if has_dialogue:\n",
        "        img_path = os.path.join(Config.dialogue_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "    else:\n",
        "        img_path = os.path.join(Config.no_dialogue_dir, f\"comic_panel_{scene_number}.bmp\")\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"‚ö†Ô∏è Image for scene {scene_number} not found at {img_path}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    image = Image.open(img_path)\n",
        "    scene_images.append(image)\n",
        "\n",
        "# ‚úÖ Combine images\n",
        "if not scene_images:\n",
        "    raise RuntimeError(\"No images found to create comic strip.\")\n",
        "\n",
        "# Dimensions for final canvas\n",
        "if Config.layout == \"horizontal\":\n",
        "    total_width = sum(img.width for img in scene_images)\n",
        "    max_height = max(img.height for img in scene_images)\n",
        "    final_image = Image.new(\"RGB\", (total_width, max_height), color=(255, 255, 255))\n",
        "\n",
        "    x_offset = 0\n",
        "    for img in scene_images:\n",
        "        final_image.paste(img, (x_offset, 0))\n",
        "        x_offset += img.width\n",
        "\n",
        "else:  # vertical layout\n",
        "    max_width = max(img.width for img in scene_images)\n",
        "    total_height = sum(img.height for img in scene_images)\n",
        "    final_image = Image.new(\"RGB\", (max_width, total_height), color=(255, 255, 255))\n",
        "\n",
        "    y_offset = 0\n",
        "    for img in scene_images:\n",
        "        final_image.paste(img, (0, y_offset))\n",
        "        y_offset += img.height\n",
        "\n",
        "# ‚úÖ Save the final comic strip\n",
        "final_image.save(Config.final_strip_path)\n",
        "print(f\"üéâ Comic strip created: {Config.final_strip_path}\")\n"
      ],
      "metadata": {
        "id": "_XtX7WPDl18P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}